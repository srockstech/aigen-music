{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46e3dba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a9ffbf2",
   "metadata": {},
   "source": [
    "# S.Rocks.Music AI Music Generation Demo\n",
    "\n",
    "This notebook demonstrates the capabilities of our AI music generation system using Meta's AudioCraft/MusicGen model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcb5039",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First, let's import the required libraries and set up our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32775cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging\n",
    "from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
    "import scipy.io.wavfile\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa06152e",
   "metadata": {},
   "source": [
    "## Model Initialization\n",
    "Now we'll load the MusicGen model and set up our device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a80f571",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Load model and processor\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/musicgen-small\")\n",
    "model = MusicgenForConditionalGeneration.from_pretrained(\n",
    "    \"facebook/musicgen-small\",\n",
    "    device_map=None,  # Let the model handle device placement\n",
    "    torch_dtype=torch.float32  # Use float32 for CPU\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c69d4e",
   "metadata": {},
   "source": [
    "## Music Generation Function\n",
    "Let's create a function to generate music from text prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc31dd73",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def generate_music(prompt, duration=10, save_path=None):\n",
    "    \"\"\"Generate music from a text prompt and return audio data.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): Text description of the desired music\n",
    "        duration (int): Duration in seconds (default: 10)\n",
    "        save_path (str, optional): Path to save the WAV file\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (sampling_rate, audio_data)\n",
    "    \"\"\"\n",
    "    print(f\"Generating {duration}-second music for prompt: '{prompt}'\")\n",
    "    \n",
    "    # Set generation parameters\n",
    "    model.generation_config.max_new_tokens = int(duration * 50)  # ~50 tokens/second\n",
    "    \n",
    "    # Process input\n",
    "    inputs = processor(\n",
    "        text=[prompt],\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Generate audio\n",
    "    with torch.no_grad():\n",
    "        audio_values = model.generate(**inputs)\n",
    "    \n",
    "    # Process output\n",
    "    sampling_rate = model.config.audio_encoder.sampling_rate\n",
    "    audio_data = audio_values[0, 0].cpu().numpy()\n",
    "    \n",
    "    # Save if path provided\n",
    "    if save_path:\n",
    "        scipy.io.wavfile.write(save_path, sampling_rate, audio_data)\n",
    "        print(f\"Audio saved to {save_path}\")\n",
    "    \n",
    "    return sampling_rate, audio_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00592aa",
   "metadata": {},
   "source": [
    "## Example 1: Basic Music Generation\n",
    "Let's generate a simple lofi beat with tabla and flute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4dcabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"lofi chill beat with tabla and flute\"\n",
    "sr, audio = generate_music(prompt, duration=10, save_path=\"demo_sample1.wav\")\n",
    "\n",
    "# Play the audio\n",
    "ipd.Audio(audio, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b94c3b0",
   "metadata": {},
   "source": [
    "## Example 2: Different Musical Style\n",
    "Now let's try something different - an electronic dance track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5303c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"upbeat electronic dance music with synth leads and heavy bass\"\n",
    "sr, audio = generate_music(prompt, duration=10, save_path=\"demo_sample2.wav\")\n",
    "\n",
    "# Play the audio\n",
    "ipd.Audio(audio, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e017f8ae",
   "metadata": {},
   "source": [
    "## Interactive Music Generation\n",
    "Use the cell below to generate music with your own prompt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d34b720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, Text, IntSlider\n",
    "\n",
    "@interact\n",
    "def generate_custom_music(prompt=Text(value=\"jazz piano solo\", description=\"Prompt:\"),\n",
    "                         duration=IntSlider(min=5, max=30, step=5, value=10, description=\"Duration (s):\")):\n",
    "    sr, audio = generate_music(prompt, duration=duration)\n",
    "    return ipd.Audio(audio, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884ff961",
   "metadata": {},
   "source": [
    "## Tips for Better Results\n",
    "\n",
    "1. **Be Specific**: Include instruments, mood, genre, and tempo in your prompts\n",
    "2. **Keep it Simple**: Don't make prompts too complex\n",
    "3. **Duration**: Longer durations take more time to generate\n",
    "4. **Experiment**: Try different combinations of instruments and styles\n",
    "\n",
    "Example prompts:\n",
    "- \"ambient pad sounds with gentle piano melodies\"\n",
    "- \"rock guitar riff with drums and bass\"\n",
    "- \"orchestral film score with strings and brass\"\n",
    "- \"traditional indian classical music with sitar\" "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
